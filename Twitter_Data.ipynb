{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "def load_api():\n",
    "    ''' Function that loads the twitter API after authorizing the user. '''\n",
    "\n",
    "    consumer_key = '8XO4C13ctzGmaXleZT2fczRbv'\n",
    "    consumer_secret = 'LiaXSL9OnO1gkEppEYWVWCUQTqwJ9ba8sW64Pc52rixpfWhYO9'\n",
    "    access_token = '915301601987919872-ihW5x7SV8dMW5lAG0nbyi69YfnmqQQl'\n",
    "    access_secret = 'xfz573YVAzIdSbMSlF5ffxLhzp6laG11vCfgCUoyWiRLd'\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    # load the twitter API via tweepy\n",
    "    return tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_search(api, query, max_tweets, max_id, since_id, geocode):\n",
    "    searched_tweets = []\n",
    "    while len(searched_tweets) < max_tweets:\n",
    "        remaining_tweets = max_tweets - len(searched_tweets)\n",
    "        try:\n",
    "            new_tweets = api.search(q=query, count=remaining_tweets,\n",
    "                                    since_id=str(since_id),\n",
    "                                    max_id=str(max_id-1))\n",
    "#                                    geocode=geocode)\n",
    "            print('found',len(new_tweets),'tweets')\n",
    "            if not new_tweets:\n",
    "                print('no tweets found')\n",
    "                break\n",
    "            searched_tweets.extend(new_tweets)\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError:\n",
    "            print('exception raised, waiting 15 minutes')\n",
    "            print('(until:', dt.datetime.now()+dt.timedelta(minutes=15), ')')\n",
    "            time.sleep(15*60)\n",
    "            break # stop the loop\n",
    "    return searched_tweets, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweet_id(api, date='', days_ago=9, query='a'):\n",
    "    ''' Function that gets the ID of a tweet. This ID can then be\n",
    "        used as a 'starting point' from which to search. The query is\n",
    "        required and has been set to a commonly used word by default.\n",
    "        The variable 'days_ago' has been initialized to the maximum\n",
    "        amount we are able to search back in time (9).'''\n",
    "    if date:\n",
    "        # return an ID from the start of the given day\n",
    "        td = date + dt.timedelta(days=1)\n",
    "        tweet_date = '{0}-{1:0>2}-{2:0>2}'.format(td.year, td.month, td.day)\n",
    "        tweet = api.search(q=query, count=1, until=tweet_date)\n",
    "    else:\n",
    "        # return an ID from __ days ago\n",
    "        td = dt.datetime.now() - dt.timedelta(days=days_ago)\n",
    "        tweet_date = '{0}-{1:0>2}-{2:0>2}'.format(td.year, td.month, td.day)\n",
    "        # get list of up to 10 tweets\n",
    "        tweet = api.search(q=query, count=10, until=tweet_date)\n",
    "        print('search limit (start/stop):',tweet[0].created_at)\n",
    "        # return the id of the first tweet in the list\n",
    "        return tweet[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_tweets(tweets, filename):\n",
    "    ''' Function that appends tweets to a file. '''\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        for tweet in tweets:\n",
    "            json.dump(tweet._json, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search phrase = Verizon\n",
      "search limit (start/stop): 2018-03-31 23:59:59\n",
      "max id (starting point) = -1\n",
      "since id (ending point) = 980233278052601856\n",
      "count = 1\n",
      "found 100 tweets\n",
      "count = 2\n",
      "found 93 tweets\n",
      "found 7 tweets\n",
      "count = 3\n",
      "found 100 tweets\n",
      "count = 4\n",
      "found 100 tweets\n",
      "count = 5\n",
      "found 100 tweets\n",
      "count = 6\n",
      "found 100 tweets\n",
      "count = 7\n",
      "found 100 tweets\n",
      "count = 8\n",
      "found 95 tweets\n",
      "found 5 tweets\n",
      "count = 9\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 10\n",
      "found 100 tweets\n",
      "count = 11\n",
      "found 100 tweets\n",
      "count = 12\n",
      "found 100 tweets\n",
      "count = 13\n",
      "found 85 tweets\n",
      "found 13 tweets\n",
      "found 2 tweets\n",
      "count = 14\n",
      "found 100 tweets\n",
      "count = 15\n",
      "found 100 tweets\n",
      "count = 16\n",
      "found 100 tweets\n",
      "count = 17\n",
      "found 76 tweets\n",
      "found 7 tweets\n",
      "found 9 tweets\n",
      "found 5 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 18\n",
      "found 43 tweets\n",
      "found 37 tweets\n",
      "found 19 tweets\n",
      "found 1 tweets\n",
      "count = 19\n",
      "found 93 tweets\n",
      "found 6 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 20\n",
      "found 99 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 21\n",
      "found 95 tweets\n",
      "found 3 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 22\n",
      "found 87 tweets\n",
      "found 2 tweets\n",
      "found 6 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 23\n",
      "found 83 tweets\n",
      "found 17 tweets\n",
      "count = 24\n",
      "found 100 tweets\n",
      "count = 25\n",
      "found 100 tweets\n",
      "count = 26\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 27\n",
      "found 100 tweets\n",
      "count = 28\n",
      "found 100 tweets\n",
      "count = 29\n",
      "found 100 tweets\n",
      "count = 30\n",
      "found 100 tweets\n",
      "count = 31\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 32\n",
      "found 95 tweets\n",
      "found 5 tweets\n",
      "count = 33\n",
      "found 100 tweets\n",
      "count = 34\n",
      "found 100 tweets\n",
      "count = 35\n",
      "found 100 tweets\n",
      "count = 36\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 37\n",
      "found 100 tweets\n",
      "count = 38\n",
      "found 100 tweets\n",
      "count = 39\n",
      "found 90 tweets\n",
      "found 9 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 40\n",
      "found 92 tweets\n",
      "found 3 tweets\n",
      "found 5 tweets\n",
      "count = 41\n",
      "found 100 tweets\n",
      "count = 42\n",
      "found 100 tweets\n",
      "count = 43\n",
      "found 100 tweets\n",
      "count = 44\n",
      "found 100 tweets\n",
      "count = 45\n",
      "found 100 tweets\n",
      "count = 46\n",
      "found 100 tweets\n",
      "count = 47\n",
      "found 100 tweets\n",
      "count = 48\n",
      "found 100 tweets\n",
      "count = 49\n",
      "found 100 tweets\n",
      "count = 50\n",
      "found 100 tweets\n",
      "count = 51\n",
      "found 100 tweets\n",
      "count = 52\n",
      "found 97 tweets\n",
      "found 3 tweets\n",
      "count = 53\n",
      "found 97 tweets\n",
      "found 3 tweets\n",
      "count = 54\n",
      "found 100 tweets\n",
      "count = 55\n",
      "found 96 tweets\n",
      "found 3 tweets\n",
      "found 1 tweets\n",
      "count = 56\n",
      "found 100 tweets\n",
      "count = 57\n",
      "found 82 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 58\n",
      "found 57 tweets\n",
      "found 42 tweets\n",
      "found 1 tweets\n",
      "count = 59\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 60\n",
      "found 87 tweets\n",
      "found 11 tweets\n",
      "found 1 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 61\n",
      "found 86 tweets\n",
      "found 14 tweets\n",
      "count = 62\n",
      "found 100 tweets\n",
      "count = 63\n",
      "found 100 tweets\n",
      "count = 64\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 65\n",
      "found 95 tweets\n",
      "found 5 tweets\n",
      "count = 66\n",
      "found 100 tweets\n",
      "count = 67\n",
      "found 100 tweets\n",
      "count = 68\n",
      "found 100 tweets\n",
      "count = 69\n",
      "found 95 tweets\n",
      "found 4 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 70\n",
      "found 100 tweets\n",
      "count = 71\n",
      "found 100 tweets\n",
      "count = 72\n",
      "found 99 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 73\n",
      "found 95 tweets\n",
      "found 5 tweets\n",
      "count = 74\n",
      "found 99 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 75\n",
      "found 100 tweets\n",
      "count = 76\n",
      "found 100 tweets\n",
      "count = 77\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 78\n",
      "found 100 tweets\n",
      "count = 79\n",
      "found 100 tweets\n",
      "count = 80\n",
      "found 100 tweets\n",
      "count = 81\n",
      "found 100 tweets\n",
      "count = 82\n",
      "found 100 tweets\n",
      "count = 83\n",
      "found 100 tweets\n",
      "count = 84\n",
      "found 100 tweets\n",
      "count = 85\n",
      "found 100 tweets\n",
      "count = 86\n",
      "found 100 tweets\n",
      "count = 87\n",
      "found 100 tweets\n",
      "count = 88\n",
      "found 100 tweets\n",
      "count = 89\n",
      "found 100 tweets\n",
      "count = 90\n",
      "found 100 tweets\n",
      "count = 91\n",
      "found 100 tweets\n",
      "count = 92\n",
      "found 100 tweets\n",
      "count = 93\n",
      "found 100 tweets\n",
      "count = 94\n",
      "found 100 tweets\n",
      "count = 95\n",
      "found 100 tweets\n",
      "count = 96\n",
      "found 100 tweets\n",
      "count = 97\n",
      "found 100 tweets\n",
      "count = 98\n",
      "found 100 tweets\n",
      "count = 99\n",
      "found 91 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 100\n",
      "found 52 tweets\n",
      "found 44 tweets\n",
      "found 4 tweets\n",
      "count = 101\n",
      "found 100 tweets\n",
      "count = 102\n",
      "found 100 tweets\n",
      "count = 103\n",
      "found 100 tweets\n",
      "count = 104\n",
      "found 100 tweets\n",
      "count = 105\n",
      "found 95 tweets\n",
      "found 5 tweets\n",
      "count = 106\n",
      "found 100 tweets\n",
      "count = 107\n",
      "found 100 tweets\n",
      "count = 108\n",
      "found 100 tweets\n",
      "count = 109\n",
      "found 100 tweets\n",
      "count = 110\n",
      "found 100 tweets\n",
      "count = 111\n",
      "found 100 tweets\n",
      "count = 112\n",
      "found 100 tweets\n",
      "count = 113\n",
      "found 100 tweets\n",
      "count = 114\n",
      "found 100 tweets\n",
      "count = 115\n",
      "found 100 tweets\n",
      "count = 116\n",
      "found 100 tweets\n",
      "count = 117\n",
      "exception raised, waiting 15 minutes\n",
      "(until: 2018-04-07 19:57:20.012740 )\n",
      "count = 118\n",
      "exception raised, waiting 15 minutes\n",
      "(until: 2018-04-07 20:12:21.540767 )\n",
      "count = 119\n",
      "found 100 tweets\n",
      "count = 120\n",
      "found 100 tweets\n",
      "count = 121\n",
      "found 100 tweets\n",
      "count = 122\n",
      "found 100 tweets\n",
      "count = 123\n",
      "found 100 tweets\n",
      "count = 124\n",
      "found 100 tweets\n",
      "count = 125\n",
      "found 100 tweets\n",
      "count = 126\n",
      "found 100 tweets\n",
      "count = 127\n",
      "found 100 tweets\n",
      "count = 128\n",
      "found 100 tweets\n",
      "count = 129\n",
      "found 100 tweets\n",
      "count = 130\n",
      "found 100 tweets\n",
      "count = 131\n",
      "found 100 tweets\n",
      "count = 132\n",
      "found 100 tweets\n",
      "count = 133\n",
      "found 100 tweets\n",
      "count = 134\n",
      "found 100 tweets\n",
      "count = 135\n",
      "found 100 tweets\n",
      "count = 136\n",
      "found 100 tweets\n",
      "count = 137\n",
      "found 100 tweets\n",
      "count = 138\n",
      "found 100 tweets\n",
      "count = 139\n",
      "found 100 tweets\n",
      "count = 140\n",
      "found 100 tweets\n",
      "count = 141\n",
      "found 100 tweets\n",
      "count = 142\n",
      "found 100 tweets\n",
      "count = 143\n",
      "found 100 tweets\n",
      "count = 144\n",
      "found 100 tweets\n",
      "count = 145\n",
      "found 100 tweets\n",
      "count = 146\n",
      "found 100 tweets\n",
      "count = 147\n",
      "found 100 tweets\n",
      "count = 148\n",
      "found 98 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 149\n",
      "found 100 tweets\n",
      "count = 150\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 151\n",
      "found 100 tweets\n",
      "count = 152\n",
      "found 100 tweets\n",
      "count = 153\n",
      "found 100 tweets\n",
      "count = 154\n",
      "found 100 tweets\n",
      "count = 155\n",
      "found 88 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 156\n",
      "found 66 tweets\n",
      "found 34 tweets\n",
      "count = 157\n",
      "found 85 tweets\n",
      "found 15 tweets\n",
      "count = 158\n",
      "found 61 tweets\n",
      "found 39 tweets\n",
      "count = 159\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 160\n",
      "found 92 tweets\n",
      "found 8 tweets\n",
      "count = 161\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 162\n",
      "found 100 tweets\n",
      "count = 163\n",
      "found 93 tweets\n",
      "found 7 tweets\n",
      "count = 164\n",
      "found 100 tweets\n",
      "count = 165\n",
      "found 100 tweets\n",
      "count = 166\n",
      "found 100 tweets\n",
      "count = 167\n",
      "found 99 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 168\n",
      "found 100 tweets\n",
      "count = 169\n",
      "found 100 tweets\n",
      "count = 170\n",
      "found 100 tweets\n",
      "count = 171\n",
      "found 100 tweets\n",
      "count = 172\n",
      "found 100 tweets\n",
      "count = 173\n",
      "found 100 tweets\n",
      "count = 174\n",
      "found 100 tweets\n",
      "count = 175\n",
      "found 100 tweets\n",
      "count = 176\n",
      "found 100 tweets\n",
      "count = 177\n",
      "found 100 tweets\n",
      "count = 178\n",
      "found 100 tweets\n",
      "count = 179\n",
      "found 100 tweets\n",
      "count = 180\n",
      "found 100 tweets\n",
      "count = 181\n",
      "found 100 tweets\n",
      "count = 182\n",
      "found 100 tweets\n",
      "count = 183\n",
      "found 100 tweets\n",
      "count = 184\n",
      "found 100 tweets\n",
      "count = 185\n",
      "found 100 tweets\n",
      "count = 186\n",
      "found 100 tweets\n",
      "count = 187\n",
      "found 100 tweets\n",
      "count = 188\n",
      "found 100 tweets\n",
      "count = 189\n",
      "found 100 tweets\n",
      "count = 190\n",
      "found 100 tweets\n",
      "count = 191\n",
      "found 100 tweets\n",
      "count = 192\n",
      "found 100 tweets\n",
      "count = 193\n",
      "found 100 tweets\n",
      "count = 194\n",
      "found 100 tweets\n",
      "count = 195\n",
      "found 100 tweets\n",
      "count = 196\n",
      "found 100 tweets\n",
      "count = 197\n",
      "found 100 tweets\n",
      "count = 198\n",
      "found 100 tweets\n",
      "count = 199\n",
      "found 100 tweets\n",
      "count = 200\n",
      "found 100 tweets\n",
      "count = 201\n",
      "found 100 tweets\n",
      "count = 202\n",
      "found 100 tweets\n",
      "count = 203\n",
      "found 100 tweets\n",
      "count = 204\n",
      "found 100 tweets\n",
      "count = 205\n",
      "found 100 tweets\n",
      "count = 206\n",
      "found 100 tweets\n",
      "count = 207\n",
      "found 100 tweets\n",
      "count = 208\n",
      "found 100 tweets\n",
      "count = 209\n",
      "found 100 tweets\n",
      "count = 210\n",
      "found 100 tweets\n",
      "count = 211\n",
      "found 100 tweets\n",
      "count = 212\n",
      "found 100 tweets\n",
      "count = 213\n",
      "found 100 tweets\n",
      "count = 214\n",
      "found 100 tweets\n",
      "count = 215\n",
      "found 100 tweets\n",
      "count = 216\n",
      "found 100 tweets\n",
      "count = 217\n",
      "found 91 tweets\n",
      "found 9 tweets\n",
      "count = 218\n",
      "found 92 tweets\n",
      "found 7 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 219\n",
      "found 56 tweets\n",
      "found 44 tweets\n",
      "count = 220\n",
      "found 100 tweets\n",
      "count = 221\n",
      "found 100 tweets\n",
      "count = 222\n",
      "found 100 tweets\n",
      "count = 223\n",
      "found 100 tweets\n",
      "count = 224\n",
      "found 100 tweets\n",
      "count = 225\n",
      "found 100 tweets\n",
      "count = 226\n",
      "found 100 tweets\n",
      "count = 227\n",
      "found 100 tweets\n",
      "count = 228\n",
      "found 100 tweets\n",
      "count = 229\n",
      "found 100 tweets\n",
      "count = 230\n",
      "found 100 tweets\n",
      "count = 231\n",
      "found 100 tweets\n",
      "count = 232\n",
      "found 100 tweets\n",
      "count = 233\n",
      "found 100 tweets\n",
      "count = 234\n",
      "found 100 tweets\n",
      "count = 235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 tweets\n",
      "count = 236\n",
      "found 100 tweets\n",
      "count = 237\n",
      "found 100 tweets\n",
      "count = 238\n",
      "found 100 tweets\n",
      "count = 239\n",
      "found 100 tweets\n",
      "count = 240\n",
      "found 100 tweets\n",
      "count = 241\n",
      "found 100 tweets\n",
      "count = 242\n",
      "found 100 tweets\n",
      "count = 243\n",
      "found 100 tweets\n",
      "count = 244\n",
      "found 100 tweets\n",
      "count = 245\n",
      "found 100 tweets\n",
      "count = 246\n",
      "found 100 tweets\n",
      "count = 247\n",
      "found 100 tweets\n",
      "count = 248\n",
      "found 100 tweets\n",
      "count = 249\n",
      "found 100 tweets\n",
      "count = 250\n",
      "found 100 tweets\n",
      "count = 251\n",
      "found 100 tweets\n",
      "count = 252\n",
      "found 100 tweets\n",
      "count = 253\n",
      "found 100 tweets\n",
      "count = 254\n",
      "found 100 tweets\n",
      "count = 255\n",
      "found 100 tweets\n",
      "count = 256\n",
      "found 100 tweets\n",
      "count = 257\n",
      "found 100 tweets\n",
      "count = 258\n",
      "found 100 tweets\n",
      "count = 259\n",
      "found 100 tweets\n",
      "count = 260\n",
      "found 100 tweets\n",
      "count = 261\n",
      "found 100 tweets\n",
      "count = 262\n",
      "found 100 tweets\n",
      "count = 263\n",
      "found 100 tweets\n",
      "count = 264\n",
      "found 100 tweets\n",
      "count = 265\n",
      "found 100 tweets\n",
      "count = 266\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 267\n",
      "found 100 tweets\n",
      "count = 268\n",
      "found 100 tweets\n",
      "count = 269\n",
      "found 100 tweets\n",
      "count = 270\n",
      "found 100 tweets\n",
      "count = 271\n",
      "found 100 tweets\n",
      "count = 272\n",
      "found 100 tweets\n",
      "count = 273\n",
      "found 100 tweets\n",
      "count = 274\n",
      "found 100 tweets\n",
      "count = 275\n",
      "found 100 tweets\n",
      "count = 276\n",
      "found 100 tweets\n",
      "count = 277\n",
      "found 100 tweets\n",
      "count = 278\n",
      "found 100 tweets\n",
      "count = 279\n",
      "found 100 tweets\n",
      "count = 280\n",
      "found 100 tweets\n",
      "count = 281\n",
      "found 100 tweets\n",
      "count = 282\n",
      "exception raised, waiting 15 minutes\n",
      "(until: 2018-04-07 20:35:40.144092 )\n",
      "count = 283\n",
      "found 100 tweets\n",
      "count = 284\n",
      "found 100 tweets\n",
      "count = 285\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 286\n",
      "found 100 tweets\n",
      "count = 287\n",
      "found 100 tweets\n",
      "count = 288\n",
      "found 100 tweets\n",
      "count = 289\n",
      "found 97 tweets\n",
      "found 3 tweets\n",
      "count = 290\n",
      "found 100 tweets\n",
      "count = 291\n",
      "found 100 tweets\n",
      "count = 292\n",
      "found 100 tweets\n",
      "count = 293\n",
      "found 100 tweets\n",
      "count = 294\n",
      "found 100 tweets\n",
      "count = 295\n",
      "found 98 tweets\n",
      "found 1 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 296\n",
      "found 98 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 297\n",
      "found 76 tweets\n",
      "found 5 tweets\n",
      "found 1 tweets\n",
      "found 18 tweets\n",
      "count = 298\n",
      "found 96 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 299\n",
      "found 97 tweets\n",
      "found 3 tweets\n",
      "count = 300\n",
      "found 92 tweets\n",
      "found 8 tweets\n",
      "count = 301\n",
      "found 99 tweets\n",
      "found 1 tweets\n",
      "count = 302\n",
      "found 98 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 303\n",
      "found 92 tweets\n",
      "found 5 tweets\n",
      "found 2 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 304\n",
      "found 88 tweets\n",
      "found 12 tweets\n",
      "count = 305\n",
      "found 96 tweets\n",
      "found 4 tweets\n",
      "count = 306\n",
      "found 100 tweets\n",
      "count = 307\n",
      "found 100 tweets\n",
      "count = 308\n",
      "found 92 tweets\n",
      "found 6 tweets\n",
      "found 2 tweets\n",
      "count = 309\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 310\n",
      "found 94 tweets\n",
      "found 6 tweets\n",
      "count = 311\n",
      "found 100 tweets\n",
      "count = 312\n",
      "found 100 tweets\n",
      "count = 313\n",
      "found 96 tweets\n",
      "found 2 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 314\n",
      "found 100 tweets\n",
      "count = 315\n",
      "found 100 tweets\n",
      "count = 316\n",
      "found 100 tweets\n",
      "count = 317\n",
      "found 100 tweets\n",
      "count = 318\n",
      "found 100 tweets\n",
      "count = 319\n",
      "found 98 tweets\n",
      "found 2 tweets\n",
      "count = 320\n",
      "found 92 tweets\n",
      "found 7 tweets\n",
      "found 1 tweets\n",
      "count = 321\n",
      "found 97 tweets\n",
      "found 2 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 322\n",
      "found 97 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 323\n",
      "found 100 tweets\n",
      "count = 324\n",
      "found 100 tweets\n",
      "count = 325\n",
      "found 61 tweets\n",
      "found 39 tweets\n",
      "count = 326\n",
      "found 100 tweets\n",
      "count = 327\n",
      "found 100 tweets\n",
      "count = 328\n",
      "found 100 tweets\n",
      "count = 329\n",
      "found 100 tweets\n",
      "count = 330\n",
      "found 100 tweets\n",
      "count = 331\n",
      "found 100 tweets\n",
      "count = 332\n",
      "found 100 tweets\n",
      "count = 333\n",
      "found 100 tweets\n",
      "count = 334\n",
      "found 100 tweets\n",
      "count = 335\n",
      "found 100 tweets\n",
      "count = 336\n",
      "found 100 tweets\n",
      "count = 337\n",
      "found 100 tweets\n",
      "count = 338\n",
      "found 100 tweets\n",
      "count = 339\n",
      "found 100 tweets\n",
      "count = 340\n",
      "found 61 tweets\n",
      "exception raised, waiting 15 minutes\n",
      "(until: 2018-04-07 20:53:35.281404 )\n",
      "count = 341\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 342\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 343\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "Search phrase = verizon\n",
      "Appending tweets to file named:  verizon/verizon_2018-04-01_to_2018-04-07.json\n",
      "Searching from the bottom ID in file\n",
      "search limit (start/stop): 2018-03-31 23:59:59\n",
      "max id (starting point) = 980233415424344065\n",
      "since id (ending point) = 980233278052601856\n",
      "count = 1\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 2\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 3\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "Search phrase = #Verizon\n",
      "search limit (start/stop): 2018-03-31 23:59:59\n",
      "max id (starting point) = -1\n",
      "since id (ending point) = 980233278052601856\n",
      "count = 1\n",
      "found 79 tweets\n",
      "found 15 tweets\n",
      "found 6 tweets\n",
      "count = 2\n",
      "found 100 tweets\n",
      "count = 3\n",
      "found 95 tweets\n",
      "found 4 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 4\n",
      "found 94 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 5\n",
      "found 96 tweets\n",
      "found 1 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 6\n",
      "found 83 tweets\n",
      "found 17 tweets\n",
      "count = 7\n",
      "found 81 tweets\n",
      "found 18 tweets\n",
      "found 1 tweets\n",
      "count = 8\n",
      "found 100 tweets\n",
      "count = 9\n",
      "found 89 tweets\n",
      "found 7 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 10\n",
      "exception raised, waiting 15 minutes\n",
      "(until: 2018-04-07 21:08:57.936303 )\n",
      "count = 11\n",
      "found 77 tweets\n",
      "found 18 tweets\n",
      "found 5 tweets\n",
      "count = 12\n",
      "found 92 tweets\n",
      "found 8 tweets\n",
      "count = 13\n",
      "found 95 tweets\n",
      "found 3 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 14\n",
      "found 87 tweets\n",
      "found 13 tweets\n",
      "count = 15\n",
      "found 89 tweets\n",
      "found 9 tweets\n",
      "found 1 tweets\n",
      "found 1 tweets\n",
      "count = 16\n",
      "found 87 tweets\n",
      "found 8 tweets\n",
      "found 5 tweets\n",
      "count = 17\n",
      "found 90 tweets\n",
      "found 10 tweets\n",
      "count = 18\n",
      "found 97 tweets\n",
      "found 2 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 19\n",
      "found 90 tweets\n",
      "found 7 tweets\n",
      "found 2 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 20\n",
      "found 83 tweets\n",
      "found 16 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 21\n",
      "found 89 tweets\n",
      "found 11 tweets\n",
      "count = 22\n",
      "found 76 tweets\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 23\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 24\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 25\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "Search phrase = #verizon\n",
      "Appending tweets to file named:  #verizon/#verizon_2018-04-01_to_2018-04-07.json\n",
      "Searching from the bottom ID in file\n",
      "search limit (start/stop): 2018-03-31 23:59:59\n",
      "max id (starting point) = 980233636208435206\n",
      "since id (ending point) = 980233278052601856\n",
      "count = 1\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 2\n",
      "found 0 tweets\n",
      "no tweets found\n",
      "count = 3\n",
      "found 0 tweets\n",
      "no tweets found\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Maximum number of empty tweet strings reached - exiting",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Maximum number of empty tweet strings reached - exiting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sugan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ''' This is a script that continuously searches for tweets\n",
    "        that were created over a given number of days. The search\n",
    "        dates and search phrase can be changed below. '''\n",
    "\n",
    "\n",
    "    ''' search variables: '''\n",
    "    search_phrases = ['Verizon','verizon','#Verizon','#verizon']\n",
    "    time_limit = 1.5                           # runtime limit in hours\n",
    "    max_tweets = 100                           # number of tweets per search (will be\n",
    "                                               # iterated over) - maximum is 100\n",
    "    min_days_old, max_days_old = 0, 7          # search limits e.g., from 7 to 8\n",
    "                                               # gives current weekday from last week,\n",
    "                                               # min_days_old=0 will search from right now\n",
    "    USA = '39.8,-95.583068847656,2500km'       # this geocode includes nearly all American\n",
    "                                               # states (and a large portion of Canada)\n",
    "    \n",
    "\n",
    "    # loop over search items,\n",
    "    # creating a new file for each\n",
    "    for search_phrase in search_phrases:\n",
    "\n",
    "        print('Search phrase =', search_phrase)\n",
    "\n",
    "        ''' other variables '''\n",
    "        name = search_phrase.split()[0]\n",
    "        json_file_root = name + '/'  + name\n",
    "        os.makedirs(os.path.dirname(json_file_root), exist_ok=True)\n",
    "        read_IDs = False\n",
    "        \n",
    "        # open a file in which to store the tweets\n",
    "        if max_days_old - min_days_old == 1:\n",
    "            d = dt.datetime.now() - dt.timedelta(days=min_days_old)\n",
    "            day = '{0}-{1:0>2}-{2:0>2}'.format(d.year, d.month, d.day)\n",
    "        else:\n",
    "            d1 = dt.datetime.now() - dt.timedelta(days=max_days_old-1)\n",
    "            d2 = dt.datetime.now() - dt.timedelta(days=min_days_old)\n",
    "            day = '{0}-{1:0>2}-{2:0>2}_to_{3}-{4:0>2}-{5:0>2}'.format(\n",
    "                  d1.year, d1.month, d1.day, d2.year, d2.month, d2.day)\n",
    "        json_file = json_file_root + '_' + day + '.json'\n",
    "        if os.path.isfile(json_file):\n",
    "            print('Appending tweets to file named: ',json_file)\n",
    "            read_IDs = True\n",
    "        \n",
    "        # authorize and load the twitter API\n",
    "        api = load_api()\n",
    "        \n",
    "        # set the 'starting point' ID for tweet collection\n",
    "        if read_IDs:\n",
    "            # open the json file and get the latest tweet ID\n",
    "            with open(json_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                max_id = json.loads(lines[-1])['id']\n",
    "                print('Searching from the bottom ID in file')\n",
    "        else:\n",
    "            # get the ID of a tweet that is min_days_old\n",
    "            if min_days_old == 0:\n",
    "                max_id = -1\n",
    "            else:\n",
    "                max_id = get_tweet_id(api, days_ago=(min_days_old-1))\n",
    "        # set the smallest ID to search for\n",
    "        since_id = get_tweet_id(api, days_ago=(max_days_old-1))\n",
    "        print('max id (starting point) =', max_id)\n",
    "        print('since id (ending point) =', since_id)\n",
    "        \n",
    "\n",
    "\n",
    "        ''' tweet gathering loop  '''\n",
    "        start = dt.datetime.now()\n",
    "        end = start + dt.timedelta(hours=time_limit)\n",
    "        count, exitcount = 0, 0\n",
    "        while dt.datetime.now() < end:\n",
    "            count += 1\n",
    "            print('count =',count)\n",
    "            # collect tweets and update max_id\n",
    "            tweets, max_id = tweet_search(api, search_phrase, max_tweets,\n",
    "                                          max_id=max_id, since_id=since_id,\n",
    "                                          geocode=USA)\n",
    "            # write tweets to file in JSON format\n",
    "            if tweets:\n",
    "                write_tweets(tweets, json_file)\n",
    "                exitcount = 0\n",
    "            else:\n",
    "                exitcount += 1\n",
    "                if exitcount == 3:\n",
    "                    if search_phrase == search_phrases[-1]:\n",
    "                        sys.exit('Maximum number of empty tweet strings reached - exiting')\n",
    "                    else:\n",
    "                        print('Maximum number of empty tweet strings reached - breaking')\n",
    "                        break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetfiles = ['Verizon_2018-04-01_to_2018-04-07.json']\n",
    "tweets=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for files in tweetfiles:\n",
    "    with open(files,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Sat Apr 07 23:37:56 +0000 2018',\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'id': 3087684921,\n",
       "    'id_str': '3087684921',\n",
       "    'indices': [0, 8],\n",
       "    'name': 'wrists slit IE',\n",
       "    'screen_name': 'jarkeem'},\n",
       "   {'id': 971980688143532032,\n",
       "    'id_str': '971980688143532032',\n",
       "    'indices': [9, 19],\n",
       "    'name': 'plant (black excellence v2)',\n",
       "    'screen_name': 'plant0024'}]},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 982764440276828161,\n",
       " 'id_str': '982764440276828161',\n",
       " 'in_reply_to_screen_name': 'jarkeem',\n",
       " 'in_reply_to_status_id': 982760913068593153,\n",
       " 'in_reply_to_status_id_str': '982760913068593153',\n",
       " 'in_reply_to_user_id': 3087684921,\n",
       " 'in_reply_to_user_id_str': '3087684921',\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'place': None,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'text': '@jarkeem @plant0024 I got Verizon too what Up',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Sun Jul 10 17:35:43 +0000 2016',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'description': '',\n",
       "  'entities': {'description': {'urls': []},\n",
       "   'url': {'urls': [{'display_url': 'Instagram.com/colton',\n",
       "      'expanded_url': 'http://Instagram.com/colton',\n",
       "      'indices': [0, 23],\n",
       "      'url': 'https://t.co/CS7HDhN2Kp'}]}},\n",
       "  'favourites_count': 42,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 360,\n",
       "  'following': False,\n",
       "  'friends_count': 155,\n",
       "  'geo_enabled': False,\n",
       "  'has_extended_profile': False,\n",
       "  'id': 752194603516919809,\n",
       "  'id_str': '752194603516919809',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 1,\n",
       "  'location': '',\n",
       "  'name': 'colton',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': None,\n",
       "  'profile_background_image_url_https': None,\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/978408699600494592/Ejb0WGmC_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/978408699600494592/Ejb0WGmC_normal.jpg',\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'coltn',\n",
       "  'statuses_count': 2290,\n",
       "  'time_zone': 'Pacific Time (US & Canada)',\n",
       "  'translator_type': 'none',\n",
       "  'url': 'https://t.co/CS7HDhN2Kp',\n",
       "  'utc_offset': -25200,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_tweet_df(tweets):\n",
    "    df = pd.DataFrame()  \n",
    "    df['tweet_id'] = list(map(lambda tweet: tweet['id'], tweets))\n",
    "    df['username'] = list(map(lambda tweet:tweet['user']['name'],tweets))\n",
    "    df['date_time'] = list(map(lambda tweet: tweet['created_at'], tweets))\n",
    "    df['text'] = list(map(lambda tweet: tweet['text'], tweets))\n",
    "    df['retweet'] = list(map(lambda tweet:True if 'retweeted_status' in tweet.keys() else False,tweets)) \n",
    "    df['retweet_count'] = list(map(lambda tweet:tweet['retweet_count'],tweets))\n",
    "    df['user_location'] = list(map(lambda tweet: tweet['user']['location'], tweets)) \n",
    "    df['country_code'] = list(map(lambda tweet: tweet['place']['country_code']\n",
    "                                  if tweet['place'] != None else '', tweets))\n",
    "    df['long'] = list(map(lambda tweet: tweet['coordinates']['coordinates'][0]\n",
    "                        if tweet['coordinates'] != None else 'NaN', tweets))\n",
    "    df['latt'] = list(map(lambda tweet: tweet['coordinates']['coordinates'][1]\n",
    "                        if tweet['coordinates'] != None else 'NaN', tweets)) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = populate_tweet_df(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## To format the text\n",
    "# de = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", df['text'][1]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    temp = TextBlob(text)\n",
    "    if(temp.sentiment.polarity > 0):\n",
    "        return \"positive\"\n",
    "    elif(temp.sentiment.polarity < 0):\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sentiment'] = df['text'].apply(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        RT @IvankaTrump: Verizon will donate $400M tha...\n",
       "1            @jarkeem @plant0024 I got Verizon too what Up\n",
       "2        One of my students father passed away while bu...\n",
       "3        RT @IvankaTrump: Verizon will donate $400M tha...\n",
       "4        RT @gavincannonn: @Verizon your service fuckin...\n",
       "5        Item specifics Condition: Used : An item that ...\n",
       "6        Item specifics Condition: Used : An item that ...\n",
       "7        iPhone X 256GB – Space Gray / Silver (Verizon)...\n",
       "8        @ChetPowell Or kids,  just so dern sexy, poor ...\n",
       "9          @TakumaSatoRacer @ISMRaceway @verizon がんばって下さい！\n",
       "10       ROLL 2 - Atmosphere - Ultimate Ears https://t....\n",
       "11       @iSmashFizzle This bothers me A LOT!!! https:/...\n",
       "12       iPhone X 256GB - Space Gray / Silver (Verizon)...\n",
       "13       Apple iPhone 6s Plus 32GB Smartphone (AT&amp;T...\n",
       "14       RT @TakumaSatoRacer: Ready to race under the l...\n",
       "15       Apple iPhone 6s Plus 32GB Smartphone (AT&amp;T...\n",
       "16       @HuffPost Some kids get trafficked  https://t....\n",
       "17       RT @JoinCellular: Can you recommend anyone for...\n",
       "18       RT @JoinCellular: Can you recommend anyone for...\n",
       "19       Good bye @verizon. Hello @projectfi. #longLive...\n",
       "20       @TaranaBurke look at this abuse  https://t.co/...\n",
       "21       Hampson is Bourdais’ “Secret Weapon” @verizon ...\n",
       "22       @TwitterMoments @TonyRobbins @TaranaBurke I wo...\n",
       "23       RT @StartPageSearch: Facebook's surveillance i...\n",
       "24       RT @TakumaSatoRacer: Ready to race under the l...\n",
       "25       Congrats to Apple and Verizon for making a new...\n",
       "26       When @Verizon says 15 minute wait time on the ...\n",
       "27       Which is your favorite and why?\\n\\nI've been e...\n",
       "28       Samsung SCH-i545 Galaxy S4 16GB Android Smartp...\n",
       "29       @JoshBoehm Private networks typically. Booster...\n",
       "                               ...                        \n",
       "33771    Don’t take my word for it, but I think #TheLie...\n",
       "33772    You should play this Two Truths game. I think ...\n",
       "33773    DO NOT MISS THIS Website, Best of High Quality...\n",
       "33774    DO NOT MISS THIS Website, Best of High Quality...\n",
       "33775    RT @schlif: I spent over 10 hrs on the phone w...\n",
       "33776    You should play this Two Truths game. I think ...\n",
       "33777    I say #TheLieIsMilk. Something just doesn’t fe...\n",
       "33778                       @verizon @drewbrees #PersibDay\n",
       "33779    You should play this Two Truths game. I think ...\n",
       "33780    Don’t take my word for it, but I think #TheLie...\n",
       "33781    RT @dentcoin: Hola México!: 100MB gratis para ...\n",
       "33782    Work From Home Customer Service Representative...\n",
       "33783    Work From Home Customer Service Representative...\n",
       "33784    @thickliviagrant “Verizon” I’m literally dead....\n",
       "33785    Verizon Communications Inc Valuation - Februar...\n",
       "33786    @szynowak @verizon Time to come back to the ma...\n",
       "33787                                @verizon @TMobile ???\n",
       "33788               @sonicdrivein @Target @verizon @Google\n",
       "33789    RT @hampgal7: @jennycohn1 ALEC is Koch's baby....\n",
       "33790    I say #TheLieIsShark. Something just doesn’t f...\n",
       "33791    I say #TheLieIsMilk. Something just doesn’t fe...\n",
       "33792    attending April Fool's Comedy Jam at Verizon T...\n",
       "33793    RT @schlif: I spent over 10 hrs on the phone w...\n",
       "33794    RT @craigbrownphd: Don’t underestimate 5G and ...\n",
       "33795    I say #TheLieIsMilk. Something just doesn’t fe...\n",
       "33796    DO NOT MISS THIS Website, Best of High Quality...\n",
       "33797    Don’t take my word for it, but I think #TheLie...\n",
       "33798    RT @visual53: Don’t take my word for it, but I...\n",
       "33799    RT @schlif: I spent over 10 hrs on the phone w...\n",
       "33800    I say #TheLieIsShark. Something just doesn’t f...\n",
       "Name: text, Length: 33801, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
